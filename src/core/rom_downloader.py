#!/usr/bin/env python3
"""
NES ROM ä¸‹è½½å’Œä¼ è¾“å·¥å…·

è¿™æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–ROMä¸‹è½½å’Œä¼ è¾“å·¥å…·ï¼Œä¸“é—¨ç”¨äºRetroPieæ¸¸æˆç³»ç»Ÿã€‚
æ”¯æŒä»åˆæ³•ROMèµ„æºç«™ä¸‹è½½æ¸¸æˆåˆé›†å¹¶è‡ªåŠ¨ä¼ è¾“åˆ°æ ‘è“æ´¾ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- ä»Archive.orgç­‰åˆæ³•èµ„æºç«™æœç´¢å’Œä¸‹è½½ROM
- æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œæ ¡éªŒå’ŒéªŒè¯
- è‡ªåŠ¨è§£å‹ZIPæ ¼å¼çš„ROMæ–‡ä»¶
- é€šè¿‡SFTPè‡ªåŠ¨ä¼ è¾“åˆ°æ ‘è“æ´¾
- å®Œæ•´çš„æ—¥å¿—è®°å½•å’Œé”™è¯¯å¤„ç†
- é…ç½®æ–‡ä»¶é©±åŠ¨çš„çµæ´»é…ç½®

ç³»ç»Ÿè¦æ±‚ï¼š
- Python 3.7+
- ç½‘ç»œè¿æ¥
- æ ‘è“æ´¾SSHè®¿é—®æƒé™

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 2.0.0
è®¸å¯è¯: MIT
"""

import argparse
import hashlib
import json
import logging
import os
import time
import zipfile
from pathlib import Path
from typing import Dict, List, Optional
from functools import lru_cache

import paramiko
import requests
from requests.adapters import HTTPAdapter
from tqdm import tqdm
from urllib3.util.retry import Retry

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler(
        "rom_downloader.log"), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


class ROMDownloader:
    """
    ROMä¸‹è½½å’Œä¼ è¾“å·¥å…·ç±»

    æä¾›å®Œæ•´çš„ROMè‡ªåŠ¨åŒ–ä¸‹è½½å’Œä¼ è¾“æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
    - ROMæœç´¢å’Œä¸‹è½½é“¾æ¥è·å–
    - æ–­ç‚¹ç»­ä¼ çš„æ–‡ä»¶ä¸‹è½½
    - æ–‡ä»¶å®Œæ•´æ€§éªŒè¯
    - è‡ªåŠ¨è§£å‹å’Œæ–‡ä»¶å¤„ç†
    - SFTPä¼ è¾“åˆ°æ ‘è“æ´¾

    å±æ€§:
        config_file (Path): é…ç½®æ–‡ä»¶è·¯å¾„
        download_dir (Path): ä¸‹è½½ç›®å½•è·¯å¾„
        config (Dict): é…ç½®å­—å…¸
        session (requests.Session): HTTPä¼šè¯å¯¹è±¡
    """

    @lru_cache(maxsize=128)
    def _get_cached_download(self, url: str) -> bytes:
        """
        Cached download method to avoid redundant downloads
        """
        try:
            response = requests.get(url, stream=True)
            response.raise_for_status()
            return response.content
        except requests.RequestException as e:
            logger.error(f"Failed to download {url}: {e}")
            raise

    def __init__(self, config_file: str = "rom_config.json"):
        """
        åˆå§‹åŒ–ROMä¸‹è½½å™¨

        Args:
            config_file (str): é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_file = Path(config_file)
        self.download_dir = Path("downloads/roms")
        self.download_dir.mkdir(parents=True, exist_ok=True)
        self.config = self._load_config()

        # è®¾ç½®é‡è¯•ç­–ç•¥
        self.session = self._setup_session()

    def _load_config(self) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if self.config_file.exists():
            try:
                with open(self.config_file, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

        # é»˜è®¤é…ç½®
        default_config = {
            "rom_sources": {
                "archive_org": {
                    "base_url": "https://archive.org",
                    "search_url": "https://archive.org/advancedsearch.php",
                    "download_patterns": ["nes-100-in-1", "nes-games-collection", "nintendo-entertainment-system-roms"],
                }
            },
            "raspberry_pi": {
                "host": "192.168.1.100",
                "port": 22,
                "username": "pi",
                "password": "",
                "key_file": "",
                "roms_path": "/home/pi/RetroPie/roms/nes/",
            },
            "download": {"timeout": 30, "chunk_size": 8192, "max_retries": 3, "retry_delay": 5},
            "verification": {"verify_checksum": True, "checksum_algorithm": "sha256"},
        }

        # ä¿å­˜é»˜è®¤é…ç½®
        self._save_config(default_config)
        return default_config

    def _save_config(self, config: Dict):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_file, "w", encoding="utf-8") as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            logger.info(f"é…ç½®æ–‡ä»¶å·²ä¿å­˜: {self.config_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

    def _setup_session(self) -> requests.Session:
        """è®¾ç½®HTTPä¼šè¯ï¼ŒåŒ…å«é‡è¯•ç­–ç•¥"""
        session = requests.Session()

        retry_strategy = Retry(
            total=self.config["download"]["max_retries"],
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "OPTIONS"],
            backoff_factor=self.config["download"]["retry_delay"],
        )

        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)

        return session

    def search_roms(self, query: str = "nes 100 in 1") -> List[Dict]:
        """æœç´¢ROMæ–‡ä»¶"""
        logger.info(f"æœç´¢ROM: {query}")

        try:
            search_url = self.config["rom_sources"]["archive_org"]["search_url"]
            params = {"q": query, "output": "json",
                      "rows": 50, "sort": "downloads desc"}

            response = self.session.get(search_url, params=params, timeout=30)
            response.raise_for_status()

            data = response.json()
            results = []

            for doc in data.get("response", {}).get("docs", []):
                if "downloads" in doc and doc["downloads"] > 0:
                    result = {
                        "identifier": doc.get("identifier", ""),
                        "title": doc.get("title", ""),
                        "description": doc.get("description", ""),
                        "downloads": doc.get("downloads", 0),
                        "files": doc.get("files", []),
                    }
                    results.append(result)

            logger.info(f"æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
            return results

        except Exception as e:
            logger.error(f"æœç´¢ROMå¤±è´¥: {e}")
            return []

    def get_download_url(self, identifier: str) -> Optional[str]:
        """è·å–ä¸‹è½½é“¾æ¥"""
        try:
            metadata_url = f"{self.config['rom_sources']['archive_org']['base_url']}/metadata/{identifier}"
            response = self.session.get(metadata_url, timeout=30)
            response.raise_for_status()

            data = response.json()
            files = data.get("files", {})

            # æŸ¥æ‰¾ZIPæ–‡ä»¶
            for filename in files.keys():
                if filename.lower().endswith(".zip"):
                    download_url = (
                        f"{self.config['rom_sources']['archive_org']['base_url']}/download/{identifier}/{filename}"
                    )
                    logger.info(f"æ‰¾åˆ°ä¸‹è½½é“¾æ¥: {download_url}")
                    return download_url

            logger.warning(f"æœªæ‰¾åˆ°ZIPæ–‡ä»¶: {identifier}")
            return None

        except Exception as e:
            logger.error(f"è·å–ä¸‹è½½é“¾æ¥å¤±è´¥: {e}")
            return None

    def download_file(self, url: str, filename: str) -> Optional[Path]:
        """ä¸‹è½½æ–‡ä»¶ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ """
        file_path = self.download_dir / filename

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if file_path.exists():
            logger.info(f"æ–‡ä»¶å·²å­˜åœ¨: {file_path}")
            return file_path

        try:
            # è·å–æ–‡ä»¶å¤§å°
            response = self.session.head(url, timeout=30)
            response.raise_for_status()

            total_size = int(response.headers.get("content-length", 0))

            # æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ†ä¸‹è½½çš„æ–‡ä»¶
            temp_path = file_path.with_suffix(".tmp")
            resume_pos = 0

            if temp_path.exists():
                resume_pos = temp_path.stat().st_size
                if resume_pos >= total_size:
                    # æ–‡ä»¶å·²å®Œæ•´ä¸‹è½½
                    temp_path.rename(file_path)
                    logger.info(f"æ–‡ä»¶ä¸‹è½½å®Œæˆ: {file_path}")
                    return file_path

            # è®¾ç½®æ–­ç‚¹ç»­ä¼ å¤´
            headers = {}
            if resume_pos > 0:
                headers["Range"] = f"bytes={resume_pos}-"
                logger.info(f"æ–­ç‚¹ç»­ä¼ : {resume_pos} bytes")

            # å¼€å§‹ä¸‹è½½
            response = self.session.get(
                url, headers=headers, stream=True, timeout=30)
            response.raise_for_status()

            mode = "ab" if resume_pos > 0 else "wb"

            with open(temp_path, mode) as f:
                with tqdm(total=total_size, initial=resume_pos, unit="B", unit_scale=True, desc=filename) as pbar:
                    for chunk in response.iter_content(chunk_size=self.config["download"]["chunk_size"]):
                        if chunk:
                            f.write(chunk)
                            pbar.update(len(chunk))

            # é‡å‘½åä¸´æ—¶æ–‡ä»¶
            temp_path.rename(file_path)
            logger.info(f"ä¸‹è½½å®Œæˆ: {file_path}")
            return file_path

        except Exception as e:
            logger.error(f"ä¸‹è½½å¤±è´¥: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_path.exists():
                temp_path.unlink()
            return None

    def verify_file(self, file_path: Path):
        """éªŒè¯æ–‡ä»¶å®Œæ•´æ€§"""
        if not self.config["verification"]["verify_checksum"]:
            return True

        logger.info(f"éªŒè¯æ–‡ä»¶å®Œæ•´æ€§: {file_path}")

        try:
            algorithm = self.config["verification"]["checksum_algorithm"]
            hash_func = getattr(hashlib, algorithm)()

            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(8192), b""):
                    hash_func.update(chunk)

            checksum = hash_func.hexdigest()
            logger.info(f"æ–‡ä»¶æ ¡éªŒå’Œ ({algorithm}): {checksum}")

            # è¿™é‡Œå¯ä»¥æ·»åŠ é¢„å®šä¹‰çš„æ ¡éªŒå’ŒéªŒè¯
            # ç”±äºROMæ–‡ä»¶å¯èƒ½æ¥è‡ªä¸åŒæºï¼Œæš‚æ—¶åªè®¡ç®—æ ¡éªŒå’Œ

            return True

        except Exception as e:
            logger.error(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            return False

    def extract_roms(self, zip_path: Path) -> List[Path]:
        """è§£å‹ROMæ–‡ä»¶"""
        logger.info(f"è§£å‹ROMæ–‡ä»¶: {zip_path}")

        rom_files = []
        extract_dir = self.download_dir / "extracted"
        extract_dir.mkdir(exist_ok=True)

        try:
            with zipfile.ZipFile(zip_path, "r") as zip_ref:
                # åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶
                file_list = zip_ref.namelist()
                logger.info(f"ZIPæ–‡ä»¶åŒ…å« {len(file_list)} ä¸ªæ–‡ä»¶")

                # è¿‡æ»¤ROMæ–‡ä»¶
                rom_extensions = [".nes", ".NES"]
                rom_files_in_zip = [f for f in file_list if any(
                    f.endswith(ext) for ext in rom_extensions)]

                logger.info(f"æ‰¾åˆ° {len(rom_files_in_zip)} ä¸ªROMæ–‡ä»¶")

                # è§£å‹ROMæ–‡ä»¶
                for rom_file in rom_files_in_zip:
                    try:
                        zip_ref.extract(rom_file, extract_dir)
                        rom_path = extract_dir / rom_file
                        rom_files.append(rom_path)
                        logger.info(f"è§£å‹: {rom_file}")
                    except Exception as e:
                        logger.error(f"è§£å‹æ–‡ä»¶å¤±è´¥ {rom_file}: {e}")

            return rom_files

        except Exception as e:
            logger.error(f"è§£å‹å¤±è´¥: {e}")
            return []

    def connect_sftp(self) -> Optional[paramiko.SSHClient]:
        """è¿æ¥SFTPæœåŠ¡å™¨"""
        logger.info("è¿æ¥æ ‘è“æ´¾SFTPæœåŠ¡å™¨...")

        try:
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())

            pi_config = self.config["raspberry_pi"]

            # ä½¿ç”¨å¯†é’¥æ–‡ä»¶æˆ–å¯†ç 
            if pi_config.get("key_file") and Path(pi_config["key_file"]).exists():
                ssh.connect(
                    hostname=pi_config["host"],
                    port=pi_config["port"],
                    username=pi_config["username"],
                    key_filename=pi_config["key_file"],
                    timeout=30,
                )
            else:
                ssh.connect(
                    hostname=pi_config["host"],
                    port=pi_config["port"],
                    username=pi_config["username"],
                    password=pi_config["password"],
                    timeout=30,
                )

            logger.info("SFTPè¿æ¥æˆåŠŸ")
            return ssh

        except Exception as e:
            logger.error(f"SFTPè¿æ¥å¤±è´¥: {e}")
            return None

    def upload_roms(self, rom_files: List[Path]):
        """ä¸Šä¼ ROMæ–‡ä»¶åˆ°æ ‘è“æ´¾"""
        if not rom_files:
            logger.warning("æ²¡æœ‰ROMæ–‡ä»¶éœ€è¦ä¸Šä¼ ")
            return False

        ssh = self.connect_sftp()
        if not ssh:
            return False

        try:
            sftp = ssh.open_sftp()
            pi_config = self.config["raspberry_pi"]
            remote_path = pi_config["roms_path"]

            # ç¡®ä¿è¿œç¨‹ç›®å½•å­˜åœ¨
            try:
                sftp.stat(remote_path)
            except FileNotFoundError:
                logger.info(f"åˆ›å»ºè¿œç¨‹ç›®å½•: {remote_path}")
                sftp.mkdir(remote_path)

            uploaded_count = 0

            for rom_file in rom_files:
                try:
                    remote_file = f"{remote_path}/{rom_file.name}"

                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                    try:
                        remote_stat = sftp.stat(remote_file)
                        local_stat = rom_file.stat()

                        if remote_stat.st_size == local_stat.st_size:
                            logger.info(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {rom_file.name}")
                            uploaded_count += 1
                            continue
                    except FileNotFoundError:
                        pass

                    # ä¸Šä¼ æ–‡ä»¶
                    logger.info(f"ä¸Šä¼ : {rom_file.name}")
                    sftp.put(str(rom_file), remote_file)
                    uploaded_count += 1

                except Exception as e:
                    logger.error(f"ä¸Šä¼ æ–‡ä»¶å¤±è´¥ {rom_file.name}: {e}")

            sftp.close()
            ssh.close()

            logger.info(f"ä¸Šä¼ å®Œæˆ: {uploaded_count}/{len(rom_files)} ä¸ªæ–‡ä»¶")
            return uploaded_count > 0

        except Exception as e:
            logger.error(f"ä¸Šä¼ è¿‡ç¨‹å‡ºé”™: {e}")
            ssh.close()
            return False

    def run(self, search_query: str = "nes 100 in 1"):
        """è¿è¡Œå®Œæ•´çš„ä¸‹è½½å’Œä¼ è¾“æµç¨‹"""
        logger.info("=== NES ROM ä¸‹è½½å’Œä¼ è¾“å·¥å…· ===")

        # 1. ä¼˜å…ˆå°è¯•é…ç½®æ–‡ä»¶ä¸­çš„ä¸‹è½½åœ°å€
        nes_zip_urls = self.config.get("nes_zip_urls", [])
        zip_path = None
        download_url = None
        if nes_zip_urls:
            logger.info(f"é…ç½®æ–‡ä»¶ä¸­æ‰¾åˆ° {len(nes_zip_urls)} ä¸ªNES ZIPä¸‹è½½åœ°å€ï¼Œä¼˜å…ˆå°è¯•...")
            for url in nes_zip_urls:
                filename = url.split("/")[-1]
                logger.info(f"å°è¯•ä¸‹è½½: {url}")
                zip_path = self.download_file(url, filename)
                if zip_path:
                    download_url = url
                    logger.info(f"æˆåŠŸä¸‹è½½: {url}")
                    break
                else:
                    logger.warning(f"ä¸‹è½½å¤±è´¥: {url}")

        # 2. å¦‚æœé…ç½®åœ°å€å…¨éƒ¨å¤±è´¥ï¼Œåˆ™è‡ªåŠ¨æœç´¢
        if not zip_path:
            logger.info("é…ç½®åœ°å€å…¨éƒ¨å¤±è´¥ï¼Œè‡ªåŠ¨æœç´¢å¯ç”¨ROM...")
            results = self.search_roms(search_query)
            if not results:
                logger.error("æœªæ‰¾åˆ°ROMæ–‡ä»¶")
                return False
            print("\næœç´¢ç»“æœ:")
            for i, result in enumerate(results[:5]):
                print(
                    f"{i+1}. {result['title']} (ä¸‹è½½æ¬¡æ•°: {result['downloads']})")
            selected_result = results[0]
            logger.info(f"é€‰æ‹©: {selected_result['title']}")
            download_url = self.get_download_url(selected_result["identifier"])
            if not download_url:
                logger.error("æ— æ³•è·å–ä¸‹è½½é“¾æ¥")
                return False
            filename = download_url.split("/")[-1]
            zip_path = self.download_file(download_url, filename)
            if not zip_path:
                logger.error("ä¸‹è½½å¤±è´¥")
                return False

        # 3. éªŒè¯æ–‡ä»¶
        if not self.verify_file(zip_path):
            logger.error("æ–‡ä»¶éªŒè¯å¤±è´¥")
            return False

        # 4. è§£å‹ROMæ–‡ä»¶
        rom_files = self.extract_roms(zip_path)
        if not rom_files:
            logger.error("è§£å‹å¤±è´¥æˆ–æœªæ‰¾åˆ°ROMæ–‡ä»¶")
            return False

        # 5. ä¸Šä¼ åˆ°æ ‘è“æ´¾
        if self.upload_roms(rom_files):
            logger.info("ROMä¼ è¾“å®Œæˆï¼")
            return True
        else:
            logger.error("ROMä¼ è¾“å¤±è´¥")
            return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="NES ROM ä¸‹è½½å’Œä¼ è¾“å·¥å…·")
    parser.add_argument("--config", default="rom_config.json", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--search", default="nes 100 in 1", help="æœç´¢å…³é”®è¯")
    parser.add_argument("--download-only", action="store_true", help="ä»…ä¸‹è½½ï¼Œä¸ä¸Šä¼ ")
    parser.add_argument("--upload-only", action="store_true", help="ä»…ä¸Šä¼ å·²ä¸‹è½½çš„æ–‡ä»¶")
    parser.add_argument("--setup-config", action="store_true", help="è®¾ç½®é…ç½®æ–‡ä»¶")

    args = parser.parse_args()

    downloader = ROMDownloader(args.config)

    if args.setup_config:
        print("è¯·ç¼–è¾‘é…ç½®æ–‡ä»¶:", args.config)
        print("é…ç½®é¡¹åŒ…æ‹¬:")
        print("- æ ‘è“æ´¾è¿æ¥ä¿¡æ¯")
        print("- ä¸‹è½½å‚æ•°")
        print("- éªŒè¯è®¾ç½®")
        return

    if args.upload_only:
        # æŸ¥æ‰¾å·²ä¸‹è½½çš„ROMæ–‡ä»¶
        extract_dir = downloader.download_dir / "extracted"
        if extract_dir.exists():
            rom_files = list(extract_dir.glob("*.nes")) + \
                list(extract_dir.glob("*.NES"))
            if rom_files:
                downloader.upload_roms(rom_files)
            else:
                logger.error("æœªæ‰¾åˆ°ROMæ–‡ä»¶")
        else:
            logger.error("æœªæ‰¾åˆ°è§£å‹ç›®å½•")
        return

    # è¿è¡Œå®Œæ•´æµç¨‹
    success = downloader.run(args.search)

    if success:
        print("\nğŸ‰ ROMä¸‹è½½å’Œä¼ è¾“å®Œæˆï¼")
    else:
        print("\nâŒ æ“ä½œå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶")

if __name__ == "__main__":
    main()
