#!/usr/bin/env python3
"""
ä»£ç åˆ†æå’Œä¼˜åŒ–å·¥å…·
è‡ªåŠ¨åˆ†æä»£ç è´¨é‡å¹¶æä¾›ä¼˜åŒ–å»ºè®®
"""

import os
import sys
import subprocess
from pathlib import Path
from typing import Dict, List, Tuple, Any

# ä¾èµ–æ£€æµ‹
def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
    required_modules = ['ast', 'json']
    missing_deps = []
    
    for module in required_modules:
        try:
            __import__(module)
        except ImportError:
            missing_deps.append(module)
    
    if missing_deps:
        print(f"âŒ ç¼ºå¤±å¿…è¦çš„æ ‡å‡†åº“æ¨¡å—: {', '.join(missing_deps)}")
        print("è¿™äº›æ˜¯Pythonæ ‡å‡†åº“æ¨¡å—ï¼Œé€šå¸¸åº”è¯¥å¯ç”¨")
        sys.exit(1)

# æ£€æŸ¥ä¾èµ–
check_dependencies()

# ç°åœ¨å¯ä»¥å®‰å…¨å¯¼å…¥
import ast
import json


class CodeAnalyzer:
    """ä»£ç åˆ†æå™¨"""

    def __init__(self, project_root: str = "."):
        """TODO: Add docstring"""
        self.project_root = Path(project_root)
        self.python_files = []
        self.analysis_results = {}

        print(f"ğŸ” ä»£ç åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")

    def scan_python_files(self) -> List[Path]:
        """æ‰«æPythonæ–‡ä»¶"""
        python_files = []

        # æ‰«ææ ¸å¿ƒç›®å½•
        for pattern in ["**/*.py"]:
            python_files.extend(self.project_root.glob(pattern))

        # è¿‡æ»¤æ‰ä¸éœ€è¦åˆ†æçš„æ–‡ä»¶
        excluded_patterns = [
            "__pycache__",
            ".git",
            "venv",
            "env",
            ".pytest_cache",
            "build",
            "dist"
        ]

        filtered_files = []
        for file_path in python_files:
            if not any(pattern in str(file_path) for pattern in excluded_patterns):
                filtered_files.append(file_path)

        self.python_files = filtered_files
        print(f"ğŸ“„ æ‰¾åˆ° {len(self.python_files)} ä¸ªPythonæ–‡ä»¶")
        return self.python_files

    def analyze_file_complexity(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†ææ–‡ä»¶å¤æ‚åº¦"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)

            # ç»Ÿè®¡ä¿¡æ¯
            stats = {
                "lines_of_code": len(content.splitlines()),
                "functions": 0,
                "classes": 0,
                "imports": 0,
                "complexity_score": 0,
                "max_function_length": 0,
                "max_class_length": 0
            }

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    stats["functions"] += 1
                    func_lines = node.end_lineno - node.lineno if hasattr(node, 'end_lineno') else 0
                    stats["max_function_length"] = max(stats["max_function_length"], func_lines)

                elif isinstance(node, ast.ClassDef):
                    stats["classes"] += 1
                    class_lines = node.end_lineno - node.lineno if hasattr(node, 'end_lineno') else 0
                    stats["max_class_length"] = max(stats["max_class_length"], class_lines)

                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    stats["imports"] += 1

                elif isinstance(node, (ast.If, ast.For, ast.While, ast.Try)):
                    stats["complexity_score"] += 1

            return stats

        except Exception as e:
            print(f"âš ï¸ åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {}

    def check_code_style(self, file_path: Path) -> List[str]:
        """æ£€æŸ¥ä»£ç é£æ ¼"""
        issues = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            for i, line in enumerate(lines, 1):
                # æ£€æŸ¥è¡Œé•¿åº¦
                if len(line.rstrip()) > 100:
                    issues.append(f"Line {i}: Line too long ({len(line.rstrip())} > 100)")

                # æ£€æŸ¥ç¼©è¿›
                if line.startswith('\t'):
                    issues.append(f"Line {i}: Use spaces instead of tabs")

                # æ£€æŸ¥å°¾éšç©ºæ ¼
                if line.rstrip() != line.rstrip(' \t'):
                    issues.append(f"Line {i}: Trailing whitespace")

        except Exception as e:
            issues.append(f"Error reading file: {e}")

        return issues

    def analyze_imports(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æå¯¼å…¥è¯­å¥"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)

            imports = {
                "standard_library": [],
                "third_party": [],
                "local": [],
                "unused_imports": [],
                "duplicate_imports": []
            }

            import_names = []

            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        import_names.append(alias.name)
                        if self.is_standard_library(alias.name):
                            imports["standard_library"].append(alias.name)
                        elif self.is_local_import(alias.name):
                            imports["local"].append(alias.name)
                        else:
                            imports["third_party"].append(alias.name)

                elif isinstance(node, ast.ImportFrom):
                    module = node.module or ""
                    import_names.append(module)
                    if self.is_standard_library(module):
                        imports["standard_library"].append(module)
                    elif self.is_local_import(module):
                        imports["local"].append(module)
                    else:
                        imports["third_party"].append(module)

            # æ£€æŸ¥é‡å¤å¯¼å…¥
            seen = set()
            for name in import_names:
                if name in seen:
                    imports["duplicate_imports"].append(name)
                seen.add(name)

            return imports

        except Exception as e:
            print(f"âš ï¸ åˆ†æå¯¼å…¥å¤±è´¥ {file_path}: {e}")
            return {}

    def is_standard_library(self, module_name: str):
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ ‡å‡†åº“æ¨¡å—"""
        standard_modules = {
            'os', 'sys', 'json', 'time', 'datetime', 'pathlib', 'subprocess',
            'threading', 'multiprocessing', 'collections', 'itertools',
            'functools', 'operator', 're', 'math', 'random', 'hashlib',
            'urllib', 'http', 'socket', 'ssl', 'email', 'html', 'xml',
            'sqlite3', 'pickle', 'csv', 'configparser', 'logging',
            'unittest', 'argparse', 'shutil', 'tempfile', 'glob'
        }

        return module_name.split('.')[0] in standard_modules

    def is_local_import(self, module_name: str):
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ¬åœ°æ¨¡å—"""
        if not module_name:
            return False

        # æ£€æŸ¥æ˜¯å¦ä¸ºç›¸å¯¹å¯¼å…¥æˆ–é¡¹ç›®å†…æ¨¡å—
        return (module_name.startswith('.') or
                (self.project_root / f"{module_name.replace('.', '/')}.py").exists() or
                (self.project_root / module_name.replace('.', '/')).is_dir())

    def generate_optimization_suggestions(self, file_path: Path, stats: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []

        # æ–‡ä»¶å¤§å°å»ºè®®
        if stats.get("lines_of_code", 0) > 500:
            suggestions.append("Consider splitting this large file into smaller modules")

        # å‡½æ•°å¤æ‚åº¦å»ºè®®
        if stats.get("max_function_length", 0) > 50:
            suggestions.append("Some functions are too long, consider breaking them down")

        # ç±»å¤æ‚åº¦å»ºè®®
        if stats.get("max_class_length", 0) > 200:
            suggestions.append("Some classes are too large, consider using composition")

        # å¤æ‚åº¦å»ºè®®
        if stats.get("complexity_score", 0) > 20:
            suggestions.append("High cyclomatic complexity, consider refactoring")

        # å¯¼å…¥å»ºè®®
        if stats.get("functions", 0) == 0 and stats.get("classes", 0) == 0:
            suggestions.append("File contains no functions or classes, consider if it's needed")

        return suggestions

    def run_analysis(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print(f"ğŸ” å¼€å§‹ä»£ç åˆ†æ...")

        # æ‰«ææ–‡ä»¶
        self.scan_python_files()

        analysis_results = {
            "summary": {
                "total_files": len(self.python_files),
                "total_lines": 0,
                "total_functions": 0,
                "total_classes": 0,
                "issues_found": 0
            },
            "files": {},
            "recommendations": []
        }

        for file_path in self.python_files:
            print(f"ğŸ“„ åˆ†ææ–‡ä»¶: {file_path.relative_to(self.project_root)}")

            # å¤æ‚åº¦åˆ†æ
            complexity = self.analyze_file_complexity(file_path)

            # ä»£ç é£æ ¼æ£€æŸ¥
            style_issues = self.check_code_style(file_path)

            # å¯¼å…¥åˆ†æ
            imports = self.analyze_imports(file_path)

            # ä¼˜åŒ–å»ºè®®
            suggestions = self.generate_optimization_suggestions(file_path, complexity)

            file_result = {
                "path": str(file_path.relative_to(self.project_root)),
                "complexity": complexity,
                "style_issues": style_issues,
                "imports": imports,
                "suggestions": suggestions
            }

            analysis_results["files"][str(file_path.relative_to(self.project_root))] = file_result

            # æ›´æ–°æ€»è®¡
            analysis_results["summary"]["total_lines"] += complexity.get("lines_of_code", 0)
            analysis_results["summary"]["total_functions"] += complexity.get("functions", 0)
            analysis_results["summary"]["total_classes"] += complexity.get("classes", 0)
            analysis_results["summary"]["issues_found"] += len(style_issues)

        # ç”Ÿæˆæ€»ä½“å»ºè®®
        analysis_results["recommendations"] = self.generate_project_recommendations(analysis_results)

        self.analysis_results = analysis_results
        print(f"âœ… ä»£ç åˆ†æå®Œæˆ")
        return analysis_results

    def generate_project_recommendations(self, results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆé¡¹ç›®çº§åˆ«çš„å»ºè®®"""
        recommendations = []

        summary = results["summary"]

        # é¡¹ç›®è§„æ¨¡å»ºè®®
        if summary["total_files"] > 50:
            recommendations.append("Large project: Consider organizing files into packages")

        if summary["total_lines"] > 10000:
            recommendations.append("Large codebase: Consider implementing automated testing")

        # ä»£ç è´¨é‡å»ºè®®
        if summary["issues_found"] > 100:
            recommendations.append("Many style issues found: Consider using automated formatters")

        # æ¶æ„å»ºè®®
        core_files = [f for f in results["files"] if "core/" in f]
        if len(core_files) > 10:
            recommendations.append("Many core files: Consider refactoring core architecture")

        return recommendations

    def save_analysis_report(self, output_file: str = "docs/code_analysis_report.json"):
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        try:
            output_path = self.project_root / output_file
            output_path.parent.mkdir(parents=True, exist_ok=True)

            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)

            print(f"ğŸ“Š åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {output_path}")
            return True

        except Exception as e:
            print(f"âŒ ä¿å­˜åˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
            return False

    def print_summary(self):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        if not self.analysis_results:
            print("âŒ æ²¡æœ‰åˆ†æç»“æœ")
            return

        summary = self.analysis_results["summary"]

        print(f"\nğŸ“Š ä»£ç åˆ†ææ‘˜è¦:")
        print(f"  ğŸ“„ æ–‡ä»¶æ€»æ•°: {summary['total_files']}")
        print(f"  ğŸ“ ä»£ç è¡Œæ•°: {summary['total_lines']}")
        print(f"  ğŸ”§ å‡½æ•°æ€»æ•°: {summary['total_functions']}")
        print(f"  ğŸ—ï¸  ç±»æ€»æ•°: {summary['total_classes']}")
        print(f"  âš ï¸  é—®é¢˜æ€»æ•°: {summary['issues_found']}")

        print(f"\nğŸ’¡ é¡¹ç›®å»ºè®®:")
        for i, rec in enumerate(self.analysis_results["recommendations"], 1):
            print(f"  {i}. {rec}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="ä»£ç åˆ†æå’Œä¼˜åŒ–å·¥å…·")
    parser.add_argument("--project-root", default=".", help="é¡¹ç›®æ ¹ç›®å½•")
    parser.add_argument("--output", default="docs/code_analysis_report.json", help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶")
    parser.add_argument("--summary-only", action="store_true", help="åªæ˜¾ç¤ºæ‘˜è¦")

    args = parser.parse_args()

    analyzer = CodeAnalyzer(args.project_root)
    results = analyzer.run_analysis()

    if args.summary_only:
        analyzer.print_summary()
    else:
        analyzer.save_analysis_report(args.output)
        analyzer.print_summary()

if __name__ == "__main__":
    main()
